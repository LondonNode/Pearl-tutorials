{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Explorers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMwxDWqoQ8hI9z9mtf+b9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LondonNode/Pearl-tutorials/blob/main/4_Explorers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLMb2ZTr9WSd"
      },
      "outputs": [],
      "source": [
        "!pip install pearll"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is a tutorial for the `explorers` module within Pearl. This module serves two functions:\n",
        "\n",
        "1. Use a random uniform policy for enhanced exploration for the first n steps of training.\n",
        "2. Add noise to the actions computed by a policy network output (e.g. in DDPG).\n",
        "\n",
        "The explorers follow the same design pattern as the updaters in the last tutorial, with an `__init__` method for initialization and a `__call__` method to run the explorer and return an action."
      ],
      "metadata": {
        "id": "909aYLZD9lXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Explorer\n",
        "\n",
        "The `BaseExplorer` acts as the base class for other explorer instances. However, it has no abstract methods, instead also serving as the explorer to use when you don't want to add any noise to the policy actions."
      ],
      "metadata": {
        "id": "_-DFjOEz-dRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pearll.explorers import BaseExplorer\n",
        "from pearll.models import Actor\n",
        "from pearll.models.encoders import IdentityEncoder\n",
        "from pearll.models.torsos import MLP\n",
        "from pearll.models.heads import DeterministicHead\n",
        "\n",
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "# model can either be an Actor or ActorCritic\n",
        "model = Actor(\n",
        "    encoder=IdentityEncoder(),\n",
        "    torso=MLP(layer_sizes=[4, 5]),\n",
        "    head=DeterministicHead(5, 1)\n",
        ")\n",
        "\n",
        "explorer = BaseExplorer(action_space=env.action_space, start_steps=10)\n",
        "# since step < start_steps, action is chosen via action_space.sample()\n",
        "random_action = explorer(model=model, observation=env.reset(), step=1)\n",
        "# since step >= start_steps, action is taken from the model\n",
        "policy_action = explorer(model=model, observation=env.reset(), step=20)"
      ],
      "metadata": {
        "id": "dmInE2l39cLc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Explorer\n",
        "\n",
        "The `GaussianExplorer` is the only other explorer class implemented right now. It has the same functionality as the `BaseExplorer` with the addition of adding 0 mean normally distributed noise to the actions from the model. The actions are then clipped to ensure the added noise doesn't push the output out of the action space range."
      ],
      "metadata": {
        "id": "KzuKb_VhBJSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pearll.explorers import GaussianExplorer\n",
        "from pearll.models import Actor\n",
        "from pearll.models.encoders import IdentityEncoder\n",
        "from pearll.models.torsos import MLP\n",
        "from pearll.models.heads import DeterministicHead\n",
        "\n",
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "# model can either be an Actor or ActorCritic\n",
        "model = Actor(\n",
        "    encoder=IdentityEncoder(),\n",
        "    torso=MLP(layer_sizes=[4, 5]),\n",
        "    head=DeterministicHead(5, 1)\n",
        ")\n",
        "\n",
        "# The scale parameter defines the std of the Gaussian noise.\n",
        "explorer = GaussianExplorer(action_space=env.action_space, scale=1, start_steps=10)\n",
        "# since step < start_steps, action is chosen via action_space.sample()\n",
        "random_action = explorer(model=model, observation=env.reset(), step=1)\n",
        "# since step >= start_steps, action is taken from the model.\n",
        "policy_action_with_noise = explorer(model=model, observation=env.reset(), step=20)"
      ],
      "metadata": {
        "id": "JrMAO2t__gAF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s8CpW9NNC_8n"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}